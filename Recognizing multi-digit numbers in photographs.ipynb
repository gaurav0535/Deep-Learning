{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = h5py.File(\"SVHN_single_grey1.h5\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h5py._hl.files.File"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data to build KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['X_train'][:3000]\n",
    "y_train = df['y_train'][:3000]\n",
    "X_test = df['X_test'][:1000]\n",
    "y_test = df['y_test'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "nsamples_test,nx_test,ny_test = X_test.shape\n",
    "X_train = X_train.reshape((nsamples,nx*ny))\n",
    "X_test = X_test.reshape((nsamples_test,nx_test*ny_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping 10% of data for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points :3000\n",
      "testing data points :1000\n"
     ]
    }
   ],
   "source": [
    "print(\"training data points :{}\".format(len(X_train)))\n",
    "print(\"testing data points :{}\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize knn with k \n",
    "\n",
    "k = range(1,30,2)\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1  Accuracy 32.1\n",
      "k= 3  Accuracy 30.7\n",
      "k= 5  Accuracy 33.300000000000004\n",
      "k= 7  Accuracy 32.800000000000004\n",
      "k= 9  Accuracy 34.599999999999994\n",
      "k= 11  Accuracy 34.5\n",
      "k= 13  Accuracy 34.4\n",
      "k= 15  Accuracy 34.699999999999996\n",
      "k= 17  Accuracy 35.4\n",
      "k= 19  Accuracy 35.0\n",
      "k= 21  Accuracy 34.8\n",
      "k= 23  Accuracy 33.300000000000004\n",
      "k= 25  Accuracy 33.5\n",
      "k= 27  Accuracy 33.6\n",
      "k= 29  Accuracy 33.2\n"
     ]
    }
   ],
   "source": [
    "#Idea is to loop over various values of k and then finding the optimal one \n",
    "\n",
    "for k in range(1,30,2):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_test,y_test)\n",
    "    print(\"k=\",k,\" Accuracy\",score*100)\n",
    "    accuracies.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model with k = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=17)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.4"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the score and then confusion matrix\n",
    "\n",
    "model.score(X_test,y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.48      0.40       117\n",
      "           1       0.31      0.56      0.40        93\n",
      "           2       0.38      0.35      0.36        92\n",
      "           3       0.30      0.31      0.30        85\n",
      "           4       0.38      0.43      0.40        96\n",
      "           5       0.36      0.19      0.25       105\n",
      "           6       0.23      0.28      0.25        94\n",
      "           7       0.61      0.53      0.57       107\n",
      "           8       0.43      0.21      0.28       100\n",
      "           9       0.28      0.21      0.24       111\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      1000\n",
      "   macro avg       0.36      0.35      0.35      1000\n",
      "weighted avg       0.37      0.35      0.35      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the classification report \n",
    "print(classification_report(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56 10  3  3 13  3 15  5  3  6]\n",
      " [ 8 52  4  4  9  4  7  3  1  1]\n",
      " [ 6 13 32 12  3  2  3  7  3 11]\n",
      " [ 8 15  6 26  3  7  7  4  2  7]\n",
      " [ 6 19  6  7 41  3  5  4  1  4]\n",
      " [12 21  5 11  4 20 12  7  7  6]\n",
      " [25  8  1  5 10  4 26  1  4 10]\n",
      " [ 3 15 11  9  4  4  2 57  0  2]\n",
      " [20  5  5  3 11  5 18  1 21 11]\n",
      " [18 11 11  8  9  3 16  5  7 23]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN is not doing any good lets do neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['X_train'][:]\n",
    "y_train = df['y_train'][:]\n",
    "X_test = df['X_test'][:]\n",
    "y_test = df['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points :42000\n",
      "testing data points :18000\n"
     ]
    }
   ],
   "source": [
    "print(\"training data points :{}\".format(len(X_train)))\n",
    "print(\"testing data points :{}\".format(len(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "nsamples_test,nx_test,ny_test = X_test.shape\n",
    "X_train = X_train.reshape((nsamples,nx*ny))\n",
    "X_test = X_test.reshape((nsamples_test,nx_test*ny_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Graph \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalise the data  \n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?tf.keras.layers.Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Graph\n",
    "\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(60, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(30, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create optimizer \n",
    "\n",
    "sgd_opt = tf.keras.optimizers.SGD(lr=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model \n",
    "\n",
    "model.compile(optimizer=sgd_opt,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 8s 198us/sample - loss: 1.4577 - accuracy: 0.5094 - val_loss: 1.1255 - val_accuracy: 0.6489\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 7s 176us/sample - loss: 1.0227 - accuracy: 0.6734 - val_loss: 0.9548 - val_accuracy: 0.7008\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 7s 166us/sample - loss: 0.8954 - accuracy: 0.7147 - val_loss: 0.8514 - val_accuracy: 0.7354\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 7s 173us/sample - loss: 0.8127 - accuracy: 0.7418 - val_loss: 0.7167 - val_accuracy: 0.7823\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 7s 171us/sample - loss: 0.7621 - accuracy: 0.7575 - val_loss: 0.6895 - val_accuracy: 0.7934\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 7s 169us/sample - loss: 0.7107 - accuracy: 0.7763 - val_loss: 0.6795 - val_accuracy: 0.8001\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 7s 172us/sample - loss: 0.6829 - accuracy: 0.7835 - val_loss: 0.6462 - val_accuracy: 0.8068\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 7s 172us/sample - loss: 0.6537 - accuracy: 0.7931 - val_loss: 0.6748 - val_accuracy: 0.7966\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 7s 177us/sample - loss: 0.6330 - accuracy: 0.8010 - val_loss: 0.6215 - val_accuracy: 0.8180\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 8s 188us/sample - loss: 0.6104 - accuracy: 0.8080 - val_loss: 0.6396 - val_accuracy: 0.8078\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 8s 189us/sample - loss: 0.6025 - accuracy: 0.8092 - val_loss: 0.5999 - val_accuracy: 0.8226\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 0.5828 - accuracy: 0.8138 - val_loss: 0.5911 - val_accuracy: 0.8246\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 0.5599 - accuracy: 0.8233 - val_loss: 0.5791 - val_accuracy: 0.8328\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 8s 190us/sample - loss: 0.5484 - accuracy: 0.8253 - val_loss: 0.5875 - val_accuracy: 0.8287\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.5394 - accuracy: 0.8269 - val_loss: 0.5908 - val_accuracy: 0.8273\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 7s 176us/sample - loss: 0.5336 - accuracy: 0.8285 - val_loss: 0.5734 - val_accuracy: 0.8328\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 7s 177us/sample - loss: 0.5184 - accuracy: 0.8354 - val_loss: 0.6098 - val_accuracy: 0.8228\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 7s 176us/sample - loss: 0.5111 - accuracy: 0.8375 - val_loss: 0.5946 - val_accuracy: 0.8241\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 7s 174us/sample - loss: 0.5063 - accuracy: 0.8402 - val_loss: 0.6027 - val_accuracy: 0.8277\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 7s 177us/sample - loss: 0.4890 - accuracy: 0.8447 - val_loss: 0.6436 - val_accuracy: 0.8158\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.4848 - accuracy: 0.8456 - val_loss: 0.5954 - val_accuracy: 0.8320\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 8s 186us/sample - loss: 0.4780 - accuracy: 0.8460 - val_loss: 0.5591 - val_accuracy: 0.8415\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 7s 178us/sample - loss: 0.4741 - accuracy: 0.8493 - val_loss: 0.5694 - val_accuracy: 0.8402\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 7s 173us/sample - loss: 0.4628 - accuracy: 0.8520 - val_loss: 0.6641 - val_accuracy: 0.8116\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 9s 203us/sample - loss: 0.4561 - accuracy: 0.8555 - val_loss: 0.5540 - val_accuracy: 0.8412\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 8s 193us/sample - loss: 0.4474 - accuracy: 0.8571 - val_loss: 0.5599 - val_accuracy: 0.8437\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 7s 170us/sample - loss: 0.4433 - accuracy: 0.8600 - val_loss: 0.6011 - val_accuracy: 0.8318\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 6s 154us/sample - loss: 0.4418 - accuracy: 0.8587 - val_loss: 0.5495 - val_accuracy: 0.8483\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 7s 162us/sample - loss: 0.4280 - accuracy: 0.8639 - val_loss: 0.6128 - val_accuracy: 0.8297\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 6s 150us/sample - loss: 0.4316 - accuracy: 0.8625 - val_loss: 0.5451 - val_accuracy: 0.8483\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 6s 149us/sample - loss: 0.4236 - accuracy: 0.8650 - val_loss: 0.5622 - val_accuracy: 0.8432\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 6s 149us/sample - loss: 0.4253 - accuracy: 0.8659 - val_loss: 0.5246 - val_accuracy: 0.8529\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 6s 152us/sample - loss: 0.4191 - accuracy: 0.8642 - val_loss: 0.5583 - val_accuracy: 0.8458\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 7s 161us/sample - loss: 0.4108 - accuracy: 0.8700 - val_loss: 0.5781 - val_accuracy: 0.8363\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 6s 154us/sample - loss: 0.4084 - accuracy: 0.8715 - val_loss: 0.5622 - val_accuracy: 0.8464\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 6s 153us/sample - loss: 0.4082 - accuracy: 0.8687 - val_loss: 0.5616 - val_accuracy: 0.8458\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 6s 151us/sample - loss: 0.3988 - accuracy: 0.8723 - val_loss: 0.5676 - val_accuracy: 0.8436\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 7s 163us/sample - loss: 0.3975 - accuracy: 0.8721 - val_loss: 0.5473 - val_accuracy: 0.8523\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 6s 149us/sample - loss: 0.3935 - accuracy: 0.8740 - val_loss: 0.5341 - val_accuracy: 0.8507\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 6s 148us/sample - loss: 0.3873 - accuracy: 0.8741 - val_loss: 0.5367 - val_accuracy: 0.8528\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 6s 150us/sample - loss: 0.3873 - accuracy: 0.8773 - val_loss: 0.5741 - val_accuracy: 0.8489\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 6s 149us/sample - loss: 0.3812 - accuracy: 0.8781 - val_loss: 0.6011 - val_accuracy: 0.8417\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 6s 152us/sample - loss: 0.3789 - accuracy: 0.8789 - val_loss: 0.6236 - val_accuracy: 0.8353\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 6s 153us/sample - loss: 0.3740 - accuracy: 0.8793 - val_loss: 0.5633 - val_accuracy: 0.8496\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 7s 157us/sample - loss: 0.3781 - accuracy: 0.8778 - val_loss: 0.5567 - val_accuracy: 0.8521\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 6s 150us/sample - loss: 0.3750 - accuracy: 0.8808 - val_loss: 0.5799 - val_accuracy: 0.8475\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 6s 149us/sample - loss: 0.3684 - accuracy: 0.8823 - val_loss: 0.5849 - val_accuracy: 0.8448\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 6s 149us/sample - loss: 0.3656 - accuracy: 0.8815 - val_loss: 0.5496 - val_accuracy: 0.8572\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 6s 148us/sample - loss: 0.3611 - accuracy: 0.8845 - val_loss: 0.5501 - val_accuracy: 0.8538\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 6s 150us/sample - loss: 0.3653 - accuracy: 0.8819 - val_loss: 0.5505 - val_accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10b3120eb38>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,\n",
    "         validation_data=(X_test,y_test),\n",
    "         epochs=50,\n",
    "         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]\n",
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.3866377e-05, 8.3509386e-03, 1.1852890e-02, 3.5921633e-03,\n",
       "       8.6426735e-06, 1.3220310e-04, 5.1556826e-03, 9.2254573e-01,\n",
       "       1.7186999e-04, 1.2442768e-03], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=np.argmax(y_predicted[0])\n",
    "y_predicted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5664899996783999, 0.8371111]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_predicted > 0.5).astype(int) \n",
    "line_y_pred=np.argmax(y_pred, axis=1)\n",
    "line_y_test=np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1764  435  317  754  371  433  366  323  554  776]\n",
      " [  11 1348   10    9   19    5    7   27    7   12]\n",
      " [   2   10 1425   19    8    8    7   56    7   13]\n",
      " [   4    4   15  869    4   11    2    5   12    6]\n",
      " [   4   10    5    3 1390    6    8    4    2   12]\n",
      " [   0    2    3   37    1 1263   45    0   12   15]\n",
      " [  16    3    3   10   10   33 1383    1   42    1]\n",
      " [   7   14   20    9    6    2    2 1390    2    6]\n",
      " [   0    2    2    7    0    6   11    1 1169   14]\n",
      " [   6    0    3    2    3    1    1    1    5  949]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(line_y_pred,line_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.29      0.45      6093\n",
      "           1       0.74      0.93      0.82      1455\n",
      "           2       0.79      0.92      0.85      1555\n",
      "           3       0.51      0.93      0.66       932\n",
      "           4       0.77      0.96      0.85      1444\n",
      "           5       0.71      0.92      0.80      1378\n",
      "           6       0.75      0.92      0.83      1502\n",
      "           7       0.77      0.95      0.85      1458\n",
      "           8       0.65      0.96      0.77      1212\n",
      "           9       0.53      0.98      0.68       971\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     18000\n",
      "   macro avg       0.72      0.88      0.76     18000\n",
      "weighted avg       0.80      0.72      0.68     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(line_y_pred,line_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upon checking the classification report we can confirm that DNN is doing far better as compared to the KNN F1 score for \n",
    "knn was in range from .25 to .57 where as in DNN model F1 score is from .45 to .85**\n",
    "\n",
    "**When we see the classification score it is 83% for DNN where as 35.4 for KNN although we took less no of data points in KNN **\n",
    "\n",
    "**Precision and recall is also low for KNN as F1 score has given clear intution **\n",
    "\n",
    "Trade off :\n",
    "\n",
    "Although we are getting good score in DNN but we don't have control over algoritham it is totally black box where as in traditional machine learning algoritham we can tell or explain how the predictions are made like in our KNN we know that we have taken 17 nearest neighbour and we will predict the class according to higher no of votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
